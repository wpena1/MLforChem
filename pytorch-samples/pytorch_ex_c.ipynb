{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Pretraining on aux task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self,n_inputs, n_hidden, n_outputs, activation):\n",
    "        super(DNN, self).__init__()\n",
    "        if type(activation) == nn.ReLU():\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "            \n",
    "        elif type(activation) == nn.LeakyReLU():\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "            \n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.model(x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "def init_weights(model):\n",
    "    if type(model) == nn.Linear:\n",
    "        nn.init.kaiming_normal_(model.weight, mode='fan_out', nonlinearity='relu')\n",
    "            #print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.concatenate((x_train,x_valid[:5000]),axis=0)\n",
    "y_train = np.concatenate((y_train,y_valid[:5000]),axis=0)\n",
    "x_valida = x_valid[:5000]\n",
    "y_valida = y_valid[:5000]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (7): ELU(alpha=1.0)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1 = DNN(784,100,1,nn.ELU())\n",
    "dnn2 = DNN(784,100,1,nn.ELU())\n",
    "loss_func = F.cross_entropy\n",
    "opt1 = optim.Adam(dnn1.model.parameters(), lr = 0.01)\n",
    "opt2 = optim.Adam(dnn2.model.parameters(), lr = 0.01)\n",
    "dnn1.apply(init_weights)\n",
    "dnn2.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = x_valid[5000:]\n",
    "y_test = y_valid[5000:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(x_train, y_train, batch_size)\n",
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2, 784)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))\n",
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 2, 784])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainb, y_trainb, X_validb, y_validb = map(\n",
    "    torch.tensor, (x_train, y_train, x_valida, y_valida)\n",
    ")\n",
    "X_testb, y_testb = map(torch.tensor,(X_test1, y_test1))\n",
    "X_testb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_early_stop(epochs, model, loss_func, opt):\n",
    "    bs = 500\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    best_loss = np.infty\n",
    "    epochs_without_progress = 0\n",
    "    running_corrects = 0.0\n",
    "    max_epochs_without_progress = 20\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for iteration in range(len(x_train) // bs):\n",
    "            X_batch, y_batch = generate_batch(x_train, y_train, bs)\n",
    "            xb, yb = map(torch.tensor,(X_batch,y_batch))\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "        print(\"loss\", loss_func(model(xb),yb).item())\n",
    "        model.eval()\n",
    "        if epoch % 5 == 0:\n",
    "            acc = accuracy(model(X_testb),y_testb)\n",
    "            print (\"accuracy\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.688275158405304\n",
      "accuracy 0.49540001153945923\n",
      "loss 0.6966156959533691\n",
      "loss 0.6919171810150146\n",
      "loss 0.6971263885498047\n",
      "loss 0.6919090151786804\n",
      "loss 0.7012786865234375\n",
      "accuracy 0.498199999332428\n",
      "loss 0.694689154624939\n",
      "loss 0.6951104998588562\n",
      "loss 0.692688524723053\n",
      "loss 0.6886424422264099\n",
      "loss 0.6903759241104126\n",
      "accuracy 0.501800000667572\n",
      "loss 0.6884114146232605\n",
      "loss 0.689602255821228\n",
      "loss 0.6947542428970337\n",
      "loss 0.691860020160675\n",
      "loss 0.696202278137207\n",
      "accuracy 0.49639999866485596\n",
      "loss 0.6943578720092773\n",
      "loss 0.691712498664856\n",
      "loss 0.6924166679382324\n",
      "loss 0.6921648979187012\n",
      "loss 0.6943737864494324\n",
      "accuracy 0.49480000138282776\n",
      "loss 0.6937608122825623\n",
      "loss 0.6947593092918396\n",
      "loss 0.6897279620170593\n",
      "loss 0.6939439177513123\n",
      "loss 0.6938048601150513\n",
      "accuracy 0.48820000886917114\n",
      "loss 0.6935588121414185\n",
      "loss 0.6930423378944397\n",
      "loss 0.6928695440292358\n",
      "loss 0.6913675665855408\n",
      "loss 0.6928569674491882\n",
      "accuracy 0.5013999938964844\n",
      "loss 0.6928838491439819\n",
      "loss 0.6928983330726624\n",
      "loss 0.6924355626106262\n",
      "loss 0.6927260160446167\n",
      "loss 0.6911967396736145\n",
      "accuracy 0.5091999769210815\n",
      "loss 0.6920173764228821\n",
      "loss 0.6928066611289978\n",
      "loss 0.6930188536643982\n",
      "loss 0.6927897930145264\n",
      "loss 0.6931599974632263\n",
      "accuracy 0.5049999952316284\n",
      "loss 0.6930373907089233\n",
      "loss 0.6936557292938232\n",
      "loss 0.694584846496582\n",
      "loss 0.6924148797988892\n",
      "loss 0.6931065917015076\n",
      "accuracy 0.4975999891757965\n",
      "loss 0.6928252577781677\n",
      "loss 0.6925060749053955\n",
      "loss 0.6923643946647644\n",
      "loss 0.6941899657249451\n",
      "loss 0.6931918859481812\n",
      "accuracy 0.5059999823570251\n",
      "loss 0.6920497417449951\n",
      "loss 0.6932860612869263\n",
      "loss 0.6930690407752991\n",
      "loss 0.693352222442627\n",
      "loss 0.6948789954185486\n",
      "accuracy 0.49900001287460327\n",
      "loss 0.6914846301078796\n",
      "loss 0.6931955814361572\n",
      "loss 0.6910055875778198\n",
      "loss 0.69298255443573\n",
      "loss 0.6930854916572571\n",
      "accuracy 0.4997999966144562\n",
      "loss 0.6933709383010864\n",
      "loss 0.6934865117073059\n",
      "loss 0.6931501626968384\n",
      "loss 0.6935533881187439\n",
      "loss 0.6930716633796692\n",
      "accuracy 0.49459999799728394\n",
      "loss 0.6931948065757751\n",
      "loss 0.6930967569351196\n",
      "loss 0.6938872337341309\n",
      "loss 0.6932239532470703\n",
      "loss 0.6929887533187866\n",
      "accuracy 0.5013999938964844\n",
      "loss 0.6932516098022461\n",
      "loss 0.6938449740409851\n",
      "loss 0.693013608455658\n",
      "loss 0.6931013464927673\n",
      "loss 0.6931225061416626\n",
      "accuracy 0.4973999857902527\n",
      "loss 0.6927993893623352\n",
      "loss 0.6933989524841309\n",
      "loss 0.6933780312538147\n",
      "loss 0.6933147311210632\n",
      "loss 0.6931490898132324\n",
      "accuracy 0.5016000270843506\n",
      "loss 0.6931254267692566\n",
      "loss 0.6931555867195129\n",
      "loss 0.6931504607200623\n",
      "loss 0.6932331919670105\n",
      "loss 0.6931349039077759\n",
      "accuracy 0.510200023651123\n",
      "loss 0.6931055784225464\n",
      "loss 0.6931536793708801\n",
      "loss 0.6931532621383667\n",
      "loss 0.6929226517677307\n",
      "loss 0.6930267810821533\n",
      "accuracy 0.49480000138282776\n",
      "loss 0.6929776072502136\n",
      "loss 0.6931905746459961\n",
      "loss 0.6931384205818176\n",
      "loss 0.6931626796722412\n",
      "loss 0.6932550072669983\n",
      "accuracy 0.503000020980835\n",
      "loss 0.6932075619697571\n",
      "loss 0.693172812461853\n",
      "loss 0.6931189894676208\n",
      "loss 0.6931446194648743\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "fit_early_stop(epochs,dnn1,loss_func,opt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitenv",
   "language": "python",
   "name": "rdkitenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

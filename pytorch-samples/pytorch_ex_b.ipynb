{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self,n_inputs, n_hidden, n_outputs, activation):\n",
    "        super(DNN, self).__init__()\n",
    "        if type(activation) == nn.ReLU():\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "            \n",
    "        elif type(activation) == nn.LeakyReLU():\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "            \n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden, n_outputs))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.0.weight',\n",
       "              tensor([[ 0.0216, -0.0265,  0.0138,  ...,  0.0306, -0.0132,  0.0301],\n",
       "                      [ 0.0286, -0.0122, -0.0140,  ..., -0.0076,  0.0306, -0.0084],\n",
       "                      [-0.0238, -0.0222, -0.0069,  ..., -0.0004, -0.0245,  0.0232],\n",
       "                      ...,\n",
       "                      [-0.0308, -0.0029, -0.0316,  ...,  0.0262, -0.0231,  0.0315],\n",
       "                      [ 0.0353,  0.0127,  0.0205,  ...,  0.0135,  0.0322,  0.0239],\n",
       "                      [-0.0011,  0.0204, -0.0049,  ..., -0.0205,  0.0117,  0.0125]])),\n",
       "             ('model.0.bias',\n",
       "              tensor([-0.5509, -0.6463, -0.4328, -0.7736, -0.8765, -0.7604, -0.6699, -0.3786,\n",
       "                      -0.5138, -1.0142,  0.1629, -0.5110, -0.3658, -0.7885, -1.0391, -0.5711,\n",
       "                       1.4764,  1.3322, -1.4863, -0.4116, -0.4133, -0.9404, -1.3470, -0.0628,\n",
       "                      -0.4701, -0.1700, -0.7294, -0.7105, -0.6562, -0.3478, -1.2315, -0.9590,\n",
       "                      -1.3270, -0.7594, -1.0116, -0.5330, -0.7382, -1.1707, -1.1997,  0.2312,\n",
       "                      -0.9013, -0.6604, -0.5277, -0.5730, -1.0342, -0.5851, -0.9936, -0.4810,\n",
       "                      -1.1334,  1.2061, -1.1664, -0.5566, -0.1732,  1.9757, -0.6076, -0.6133,\n",
       "                      -1.1770, -1.2466, -0.3652, -0.7732, -0.9922, -0.6827, -0.7807, -0.9893,\n",
       "                      -0.4627, -1.0384, -0.4325, -0.9806, -0.8791, -0.6735, -0.9927, -1.5163,\n",
       "                      -0.3045, -0.8455, -0.7189, -0.6001, -0.5391, -1.4410, -0.8921, -1.1504,\n",
       "                      -0.8793, -1.3242, -0.6558, -0.9314,  2.7092, -0.5812, -0.0204, -0.6190,\n",
       "                      -1.4278, -0.6301, -0.7542, -0.7543,  0.0268, -1.2446, -1.1088, -0.7177,\n",
       "                      -1.1745, -0.6962, -1.1361, -0.5162])),\n",
       "             ('model.2.weight',\n",
       "              tensor([[ 1.3610,  0.8121,  0.2768,  ...,  0.8305,  0.8815, -0.1106],\n",
       "                      [ 1.0214,  1.1993,  0.6813,  ...,  1.3384,  1.6807,  0.5584],\n",
       "                      [ 0.7370,  0.4702, -0.5167,  ...,  0.6625,  0.3648,  1.3853],\n",
       "                      ...,\n",
       "                      [ 1.1404,  0.9506,  0.4577,  ...,  1.0094,  0.7483,  0.7415],\n",
       "                      [ 0.5581,  0.6339, -0.1704,  ...,  1.0638,  0.7090,  1.2263],\n",
       "                      [ 1.0644,  0.9352, -0.6904,  ...,  1.3995,  1.0888,  0.2854]])),\n",
       "             ('model.2.bias',\n",
       "              tensor([-0.9276, -1.3065, -0.7443, -2.1664, -0.6334, -1.0098, -0.9468, -1.4004,\n",
       "                      -1.6014, -1.8299, -0.7276, -1.1870, -0.5122, -0.9672, -1.4367, -2.2880,\n",
       "                      -1.8056, -1.4688, -1.3818, -0.1339, -1.7777, -1.9747, -1.3818, -1.3993,\n",
       "                      -0.8872, -1.5656, -1.6658, -2.1689, -1.8084, -1.3948, -1.7193, -1.4047,\n",
       "                      -1.5766, -1.4471, -1.4913, -0.9112, -1.0587, -1.5747, -1.6803, -1.0944,\n",
       "                      -0.7625, -1.3186, -0.6770, -1.4864, -1.0818, -0.9570, -1.4998, -0.4321,\n",
       "                      -1.7316, -1.4078, -0.3773, -1.6194, -1.7612,  2.0531, -0.4065, -1.6597,\n",
       "                      -1.2763, -1.5251, -1.4057, -2.1208, -0.4885, -1.7432, -0.9890, -1.1823,\n",
       "                      -1.9078, -0.8697, -1.3032, -0.2454, -0.5467, -0.9370, -1.3051, -1.2687,\n",
       "                      -2.1305,  0.8304,  0.0049,  0.3238, -1.8851, -0.7024, -1.6798, -0.3192,\n",
       "                      -0.4074, -1.3227, -1.3613, -1.9985,  0.5181, -0.3381, -1.6275, -1.2272,\n",
       "                      -1.5232, -1.6751, -1.5416, -0.8808, -0.7185, -1.0880, -1.5094, -0.6057,\n",
       "                      -2.0153, -1.2787, -1.1986, -1.4899])),\n",
       "             ('model.4.weight',\n",
       "              tensor([[ 0.5486,  0.1884,  0.2153,  ...,  0.6192, -1.0796,  0.4028],\n",
       "                      [-0.4955, -0.7199,  0.0587,  ...,  1.0782,  0.4206, -0.0055],\n",
       "                      [-0.7399, -0.6691,  0.6996,  ...,  1.5882,  0.3535, -0.0792],\n",
       "                      ...,\n",
       "                      [-0.0554, -0.5043,  0.8023,  ...,  2.2535, -0.0670,  0.7268],\n",
       "                      [ 0.1484,  0.1239,  0.1231,  ...,  2.3564, -0.0749,  0.6291],\n",
       "                      [ 1.0083,  1.2361,  0.6858,  ...,  1.0993, -0.4967,  0.7345]])),\n",
       "             ('model.4.bias',\n",
       "              tensor([-0.9485, -1.0740, -1.8654, -0.9759, -2.3688, -1.0008,  0.0422, -1.5310,\n",
       "                      -1.0298, -1.9742, -0.0070, -1.5139, -2.3005, -0.5069, -1.3725, -2.0266,\n",
       "                      -0.6863, -2.2028, -0.9551, -0.7745, -1.4575, -2.2065, -1.5543, -1.0218,\n",
       "                      -2.5030, -1.6275, -2.0949, -0.9090, -0.6598, -0.6206, -2.8158, -2.4043,\n",
       "                      -0.8654, -2.7449, -0.9711, -1.1043, -1.7863, -1.6970, -2.4348, -0.6732,\n",
       "                      -1.8347, -2.7222, -1.0519, -2.3399,  0.9285, -2.0812,  0.8071,  1.0677,\n",
       "                      -1.1759, -0.4394, -2.5362, -2.9373, -1.5505, -1.8653, -1.5912, -0.7191,\n",
       "                      -1.4598, -1.9583, -1.1576, -2.0571, -1.6656, -0.5856, -2.2607, -0.9883,\n",
       "                      -1.5874, -2.5147, -1.8607, -0.4841, -1.8984, -0.7116, -1.3721, -1.1109,\n",
       "                      -1.4154, -1.6131, -1.6952, -2.4197, -1.6981, -0.1441, -1.4584, -2.7401,\n",
       "                      -2.1302, -1.8188, -2.0698, -2.6422,  0.1538, -1.3528, -1.8791, -1.7568,\n",
       "                      -0.7667, -2.0091, -0.7735, -1.7629, -2.5040, -2.0740, -1.5952, -2.3591,\n",
       "                      -1.7431, -2.5330, -2.4692, -1.7563])),\n",
       "             ('model.6.weight',\n",
       "              tensor([[ 0.3397,  0.2071, -0.4525,  ..., -0.1164,  0.1018, -0.0441],\n",
       "                      [ 0.4086,  0.3505, -0.0262,  ..., -0.4906,  0.1569, -0.0519],\n",
       "                      [-0.1145, -0.1846, -0.6762,  ...,  0.0177, -0.2220,  0.1346],\n",
       "                      ...,\n",
       "                      [ 0.0371,  0.7036,  0.1108,  ...,  0.2805,  0.2006, -0.0324],\n",
       "                      [-0.1533,  1.1789,  0.1446,  ...,  0.5185,  0.2978,  0.6072],\n",
       "                      [ 0.1800, -0.1391, -0.0322,  ...,  0.5048, -0.4514,  0.0765]])),\n",
       "             ('model.6.bias',\n",
       "              tensor([-1.1186, -1.1001, -1.3571, -1.7159, -1.5578, -1.2271, -1.8929, -1.4006,\n",
       "                      -1.7350, -1.1493, -1.7245, -0.7151, -1.7519, -1.2096, -2.1744, -1.9398,\n",
       "                      -0.6806, -1.3109, -0.9817, -2.0080, -1.3251,  0.0904, -1.8493, -1.3373,\n",
       "                      -1.3218, -1.0547, -1.5421, -1.8874, -0.4833, -0.6448, -1.6240, -1.2924,\n",
       "                      -1.1340, -1.8874, -0.8818, -1.8335, -1.2445, -0.0874, -1.0101, -0.8886,\n",
       "                      -1.2184, -1.4990, -1.3466, -1.3116, -1.9535, -1.6601, -0.9869, -1.7743,\n",
       "                      -0.7358, -1.2826,  0.1432, -1.7764, -1.1245, -1.9866, -1.8842, -1.4857,\n",
       "                      -0.8258, -1.4204, -1.0969, -2.0298, -1.8015, -1.0957, -1.0618, -1.3477,\n",
       "                      -1.2260, -0.9858, -1.5501, -0.8057, -1.0629, -2.0628, -1.2781, -1.5400,\n",
       "                      -1.2188, -1.7645, -1.0372, -1.5122, -0.7227, -1.7218, -1.5719,  0.0356,\n",
       "                      -1.2211, -1.7243, -0.8793, -0.9591, -1.7463, -0.3170, -1.0807, -0.7690,\n",
       "                      -1.5987, -1.8897, -1.1085, -1.3550, -0.4207, -1.2779, -1.9904, -1.8617,\n",
       "                      -1.3277, -1.9777, -0.7471, -1.5885])),\n",
       "             ('model.8.weight',\n",
       "              tensor([[ 2.0863e-01,  8.4361e-02, -2.1580e-01, -7.9383e-01, -2.2684e-01,\n",
       "                        4.4578e-01, -9.8513e-02,  1.7901e-02, -2.4291e-01,  7.3298e-02,\n",
       "                        2.5294e-01, -5.3664e-02,  2.8342e-01, -1.0443e-01,  2.5702e-01,\n",
       "                       -1.6362e-02,  3.7229e-02,  1.4319e-01, -2.2769e-01,  6.3602e-02,\n",
       "                        1.8126e-02,  1.9595e-01, -6.9102e-02,  2.9643e-01, -1.6026e-01,\n",
       "                       -3.6825e-01,  1.7511e-01,  1.5251e-01,  1.5807e-01, -1.7690e-02,\n",
       "                        1.7437e-01, -3.9756e-02, -8.7865e-03, -3.3390e-01,  5.0864e-03,\n",
       "                       -5.1483e-01,  3.7950e-01,  2.3028e-01,  2.1051e-01,  1.0047e-01,\n",
       "                       -7.5197e-02, -2.5737e-01,  3.6684e-01,  3.5977e-01,  1.2342e-01,\n",
       "                        4.4982e-01,  8.1872e-02,  4.2010e-01, -5.0071e-02, -3.1356e-01,\n",
       "                        8.8127e-02,  1.7321e-02, -6.1837e-02,  2.7421e-01,  8.3073e-02,\n",
       "                        4.1097e-01, -6.0096e-01,  8.2986e-02, -2.5401e-01,  4.8019e-01,\n",
       "                       -2.8509e-01,  4.0794e-01, -2.8628e-01,  4.8281e-02, -1.7313e-01,\n",
       "                        4.1370e-01,  2.7528e-01,  4.7244e-01,  2.7201e-01, -3.0949e-01,\n",
       "                        1.0083e-02, -1.7236e-01,  5.1768e-01,  1.2718e-01,  2.3300e-01,\n",
       "                       -3.4911e-01,  2.8826e-02,  2.3489e-01,  5.6629e-01,  1.9608e-02,\n",
       "                        8.4727e-02,  2.6431e-01,  1.1700e-01, -2.2209e-01,  3.8124e-01,\n",
       "                        9.2123e-02,  4.0988e-01,  2.8101e-01,  2.9244e-01, -6.3682e-02,\n",
       "                       -1.3828e-02,  3.1116e-01,  8.9955e-02,  3.4074e-01, -8.2510e-02,\n",
       "                        2.1750e-02,  1.7656e-01, -5.8588e-02,  3.5230e-01, -2.1921e-01],\n",
       "                      [-1.7036e-02, -9.9295e-02,  1.5167e-01, -3.4531e-01,  1.9836e-02,\n",
       "                       -1.8623e-01,  5.1016e-02,  9.8512e-02,  4.3481e-02, -5.9409e-02,\n",
       "                       -2.7143e-01, -7.7735e-02, -1.7048e-01, -3.9049e-02, -1.4511e-01,\n",
       "                       -8.4377e-02,  1.3390e+00,  1.4283e-01, -1.3637e-01, -2.0500e-02,\n",
       "                       -2.7764e-01, -9.0074e-02,  1.0935e-01, -2.3218e-01, -4.3091e-02,\n",
       "                       -1.4369e-01,  2.4303e-01, -2.4713e-01, -3.2606e-01,  1.5445e+00,\n",
       "                        7.2325e-02,  8.2093e-02, -6.5820e-02,  9.9318e-02, -6.5887e-02,\n",
       "                       -3.7262e-02,  3.9283e-01, -5.4167e-02,  1.1044e-01,  1.5584e-01,\n",
       "                       -2.1072e-01,  5.7691e-02, -9.9121e-02, -1.4862e-01, -3.3841e-01,\n",
       "                        1.6370e-02,  8.1443e-02,  1.8771e-01,  1.5272e+00, -2.5937e-04,\n",
       "                       -1.5266e-01, -1.5239e-01, -1.5330e-01, -5.6357e-02, -1.2881e-01,\n",
       "                        1.2441e-01, -1.0525e-01,  3.1466e-01, -3.4482e-01,  4.5268e-02,\n",
       "                        1.0465e-01,  7.9474e-02, -1.3811e-01, -1.4773e-01, -1.7276e-01,\n",
       "                       -1.2937e-01, -2.0561e-01, -2.9097e-01, -4.7010e-01, -1.5875e-01,\n",
       "                       -1.3995e-01, -6.0823e-02, -2.7415e-02,  3.6523e-02, -3.6589e-01,\n",
       "                       -2.8823e-02, -2.7058e-01, -3.3262e-01, -7.8314e-02,  1.6524e-01,\n",
       "                       -4.3318e-01,  4.3868e-02, -3.9516e-01, -1.8499e-01,  3.8004e-02,\n",
       "                       -4.2162e-02,  1.0466e-01, -4.3217e-01, -2.3066e-02,  7.4562e-02,\n",
       "                       -5.1237e-02, -1.1801e-01, -2.9423e-01, -2.0605e-01,  9.4355e-02,\n",
       "                        2.7681e-02,  8.2518e-03, -1.8503e-01, -6.2950e-02,  5.8186e-02],\n",
       "                      [ 3.9505e-01, -3.0380e-02,  1.3498e-01,  6.8084e-02,  2.8878e-01,\n",
       "                       -6.6927e-02,  2.2651e-01, -3.5897e-02,  3.6163e-02,  3.8952e-01,\n",
       "                        8.6932e-02,  6.4828e-02,  1.2224e-01,  1.1666e-01, -5.1599e-02,\n",
       "                        2.2338e-01, -8.5552e-01,  5.8923e-02,  3.0141e-01,  2.1511e-01,\n",
       "                        2.3907e-01,  6.0174e-03,  3.0676e-01,  2.1597e-01,  3.3605e-01,\n",
       "                        2.1331e-01,  4.6145e-01,  8.3187e-02, -5.9181e-02, -1.7480e+00,\n",
       "                        1.6405e-01,  2.1558e-01,  2.3561e-01,  2.6530e-01,  2.8640e-02,\n",
       "                        2.1983e-01,  2.4432e-01,  1.7975e-01,  3.4731e-01,  2.7618e-01,\n",
       "                        2.5986e-01,  1.4958e-01,  1.8644e-01,  2.0797e-02,  9.3312e-02,\n",
       "                        1.4929e-01,  5.6152e-02,  4.2756e-01, -1.1456e+00,  2.5588e-01,\n",
       "                        3.3625e-01,  3.9584e-01,  1.8086e-01,  3.9080e-01,  1.2620e-01,\n",
       "                        6.0378e-02,  9.7767e-02,  3.0932e-01,  2.1616e-01,  3.2114e-01,\n",
       "                        1.8298e-01,  2.4204e-01,  1.8700e-01,  2.1541e-01,  4.6815e-01,\n",
       "                        2.9272e-01,  4.4740e-01,  2.4110e-01,  3.9499e-02,  3.3018e-01,\n",
       "                       -6.4391e-02, -3.2325e-03, -2.1610e-01,  2.3376e-01,  1.0471e-01,\n",
       "                        2.8425e-01,  2.3403e-01,  2.2073e-01,  7.3135e-02,  2.4666e-01,\n",
       "                        1.7189e-01,  2.7291e-01, -2.0199e-02,  1.2950e-01,  2.2436e-01,\n",
       "                        1.8825e-01,  3.5680e-01,  9.3541e-02,  2.7629e-01,  3.7419e-01,\n",
       "                        3.4796e-02,  2.6621e-01,  2.3652e-01,  2.8201e-01,  7.3537e-02,\n",
       "                        2.1132e-01,  2.3173e-01,  3.5109e-01, -3.5419e-01,  2.3460e-01],\n",
       "                      [-1.4535e-01,  4.8825e-04,  1.0331e-01,  9.2537e-02,  1.7300e-01,\n",
       "                       -2.0026e-01, -1.0887e-03,  3.7120e-02, -4.8017e-02, -1.2548e-01,\n",
       "                        1.4857e-01,  3.7936e-01,  1.1196e-01, -2.0005e-01, -7.6966e-02,\n",
       "                        2.8279e-02,  3.0222e-01, -3.4124e-01,  4.1417e-01, -6.3183e-02,\n",
       "                        2.4860e-01, -1.6326e-01,  2.3505e-01,  3.4449e-01, -4.4141e-01,\n",
       "                       -1.9470e-01, -1.9741e-01,  2.4493e-02,  2.4882e-01, -1.3996e-01,\n",
       "                       -1.2144e-01, -7.7058e-02, -1.2409e-01, -1.4378e-01, -1.4047e-01,\n",
       "                        4.9293e-01,  2.6564e-01,  1.8446e-01, -1.5464e-01,  4.1422e-01,\n",
       "                        4.5815e-01, -5.3413e-02, -9.1173e-02, -4.7973e-02, -1.5727e-01,\n",
       "                       -3.0225e-01,  1.6542e-01,  1.4260e-02,  2.8485e-01, -1.6238e-01,\n",
       "                        1.5874e-01,  1.8527e-01,  1.6471e-01,  2.3498e-01, -4.2593e-02,\n",
       "                       -4.0751e-02,  3.0633e-02, -1.9756e-01,  2.3719e-01,  2.3337e-01,\n",
       "                       -1.3288e-01, -1.2124e-01,  2.5938e-01, -9.9779e-02, -7.6447e-02,\n",
       "                       -4.4594e-02,  4.3379e-03,  2.2823e-01,  3.5110e-01, -1.4124e-01,\n",
       "                       -2.8381e-01,  2.6179e-02, -2.8176e-01, -1.2765e-01,  1.1287e-01,\n",
       "                        4.2742e-01,  4.7787e-01, -2.3245e-02,  2.0753e-01,  4.2190e-01,\n",
       "                        4.3228e-01,  2.8283e-01,  3.4861e-01,  4.2384e-01,  3.5407e-01,\n",
       "                       -2.6956e-01, -2.0768e-02,  3.0818e-01, -7.9312e-03, -1.7938e-01,\n",
       "                       -6.8444e-02, -1.4742e-01,  4.0982e-01,  1.2618e-02,  1.4533e-01,\n",
       "                        4.3843e-02,  4.8572e-01,  7.9891e-02,  1.5005e-01,  4.8498e-02],\n",
       "                      [-1.4067e-02,  7.8945e-02,  5.1032e-02,  3.8414e-01, -2.3989e-01,\n",
       "                        2.3289e-01, -3.2244e-01,  1.0612e-01, -2.2934e-01,  2.7966e-01,\n",
       "                       -1.7705e-01, -2.3349e-01, -2.6199e-01,  1.6421e-01, -9.1185e-02,\n",
       "                       -4.5218e-02,  1.3640e-02,  2.7133e-01, -2.0914e-01, -4.5829e-01,\n",
       "                       -1.8142e-01, -3.3258e-02, -2.2395e-02,  5.4341e-02,  7.8117e-01,\n",
       "                        2.0593e-01, -5.9307e-02, -1.1904e-04,  1.7446e-01,  7.2896e-02,\n",
       "                       -1.8599e-01, -1.3312e-01,  2.3788e-01,  1.5954e-01,  1.5342e-01,\n",
       "                        2.2017e-01,  2.6442e-01,  3.9650e-01, -1.4132e-01, -1.6965e-01,\n",
       "                        1.6409e-01,  2.2744e-01, -3.9374e-01, -1.6897e-01, -2.6672e-01,\n",
       "                        1.9297e-01, -2.7767e-01, -2.9535e-02,  3.6907e-02,  3.1849e-01,\n",
       "                        1.5060e-01, -7.4834e-02, -2.3891e-02,  2.5395e-01, -3.9525e-01,\n",
       "                       -7.6396e-02,  1.7623e-01,  2.2145e-01,  2.6052e-01,  1.2726e-01,\n",
       "                        7.5315e-02, -1.8356e-01, -1.1430e-01, -9.0994e-02,  5.9175e-01,\n",
       "                        4.7485e-01,  5.4921e-01, -1.6106e-01,  2.7026e-01,  1.0843e+00,\n",
       "                        6.7212e-01,  1.7811e-01, -6.1443e-02,  3.1837e-01,  5.4313e-01,\n",
       "                       -2.7842e-02,  2.3554e-02,  1.2687e-01,  1.3709e-01,  2.0162e-01,\n",
       "                        5.0643e-02, -1.3719e-01,  1.9386e-01, -6.8329e-02,  1.5681e-01,\n",
       "                        3.4195e-01, -2.9812e-01,  4.3043e-03, -3.0237e-01, -5.9425e-02,\n",
       "                        2.2231e-02, -3.9421e-01, -1.8226e-01, -2.5996e-01, -8.8454e-02,\n",
       "                       -1.1549e-01,  1.9207e-01,  2.1797e-01,  4.2479e-01,  1.7548e-01]])),\n",
       "             ('model.8.bias',\n",
       "              tensor([ 0.0773, -2.4059,  1.9815, -0.2125,  0.0214]))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden = 100\n",
    "n_outputs = 5\n",
    "activation = nn.ELU()\n",
    "model = DNN(n_inputs, n_hidden, n_outputs, activation)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "PATH = \"./vannilla.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    if count < 3:\n",
    "        param.requires_grad = False\n",
    "    count += 1\n",
    "extraLayer = nn.Linear(5,5)\n",
    "new_model = nn.Sequential(model, extraLayer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train,x_valid[:5000]),axis=0)\n",
    "y_train = np.concatenate((y_train,y_valid[:5000]),axis=0)\n",
    "x_valid = x_valid[:5000]\n",
    "y_valid = y_valid[:5000]\n",
    "\n",
    "X_train_five_nine = x_train[y_train >= 5]\n",
    "y_train_five_nine = y_train[y_train >= 5] - 5\n",
    "X_valid_five_nine = x_valid[y_valid >= 5]\n",
    "y_valid_five_nine = y_valid[y_valid >= 5] - 5\n",
    "\n",
    "X_train_five_nineb, y_train_five_nineb = sample_n_instances_per_class(X_train_five_nine, y_train_five_nine, n=100)\n",
    "X_valid_five_nineb, y_valid_five_nineb = sample_n_instances_per_class(X_valid_five_nine, y_valid_five_nine,n=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_five_nineb, y_train_five_nineb, X_valid_five_nineb, y_valid_five_nineb = map(\n",
    "    torch.tensor, (X_train_five_nineb, y_train_five_nineb, X_valid_five_nineb, y_valid_five_nineb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_early_stop(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    bs = 20\n",
    "    best_loss = np.infty\n",
    "    epochs_without_progress = 0\n",
    "    max_epochs_without_progress = 20\n",
    "    PATH = './bestmodeltorch.pth'\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb_val, yb_val) for xb_val, yb_val in valid_dl]\n",
    "            )\n",
    "            \n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        val_accuracy = accuracy(model(X_valid_five_nineb),y_valid_five_nineb)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch:\", epoch,\n",
    "                  \"\\tValidation accuracy: {:.3f}%\".format(val_accuracy * 100),\n",
    "                  \"\\tLoss: {:.5f}\".format(val_loss))\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'loss': loss_func,\n",
    "            }, PATH)\n",
    "            epochs_without_progress = 0\n",
    "        else:\n",
    "            epochs_without_progress += 1\n",
    "            if epochs_without_progress > max_epochs_without_progress:\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 784])\n",
      "torch.Size([500])\n",
      "torch.Size([150, 784])\n",
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "n, c = X_train_five_nineb.shape\n",
    "print (X_train_five_nineb.shape)\n",
    "print (y_train_five_nineb.shape)\n",
    "print (X_valid_five_nineb.shape)\n",
    "print (y_valid_five_nineb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 30\n",
    "n_batches = int(np.ceil( n / bs))\n",
    "\n",
    "train_ds = TensorDataset(X_train_five_nineb, y_train_five_nineb)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(X_valid_five_nineb, y_valid_five_nineb)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 24.667% \tLoss: 1.93811\n",
      "Epoch: 5 \tValidation accuracy: 30.000% \tLoss: 1.54846\n",
      "Epoch: 10 \tValidation accuracy: 30.667% \tLoss: 1.61198\n",
      "Epoch: 15 \tValidation accuracy: 30.000% \tLoss: 1.57903\n",
      "Epoch: 20 \tValidation accuracy: 32.667% \tLoss: 1.77533\n",
      "Epoch: 25 \tValidation accuracy: 35.333% \tLoss: 1.68716\n",
      "Epoch: 30 \tValidation accuracy: 24.000% \tLoss: 1.59105\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "extraLayer = nn.Linear(5,5)\n",
    "new_model = nn.Sequential(model, extraLayer)\n",
    "epochs = 100\n",
    "fit_early_stop(epochs, new_model, loss, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 24.000% \tLoss: 1.91916\n",
      "Epoch: 5 \tValidation accuracy: 65.333% \tLoss: 0.97875\n",
      "Epoch: 10 \tValidation accuracy: 62.000% \tLoss: 1.21565\n",
      "Epoch: 15 \tValidation accuracy: 64.000% \tLoss: 0.87364\n",
      "Epoch: 20 \tValidation accuracy: 72.000% \tLoss: 0.86426\n",
      "Epoch: 25 \tValidation accuracy: 63.333% \tLoss: 1.21268\n",
      "Epoch: 30 \tValidation accuracy: 72.000% \tLoss: 1.07909\n",
      "Epoch: 35 \tValidation accuracy: 76.000% \tLoss: 1.14182\n",
      "Epoch: 40 \tValidation accuracy: 70.000% \tLoss: 1.28007\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "fit_early_stop(epochs, model, loss, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 31.333% \tLoss: 1.55632\n",
      "Epoch: 5 \tValidation accuracy: 38.667% \tLoss: 1.52450\n",
      "Epoch: 10 \tValidation accuracy: 41.333% \tLoss: 1.51208\n",
      "Epoch: 15 \tValidation accuracy: 41.333% \tLoss: 1.50700\n",
      "Epoch: 20 \tValidation accuracy: 40.667% \tLoss: 1.50052\n",
      "Epoch: 25 \tValidation accuracy: 41.333% \tLoss: 1.51017\n",
      "Epoch: 30 \tValidation accuracy: 38.667% \tLoss: 1.52197\n",
      "Epoch: 35 \tValidation accuracy: 38.667% \tLoss: 1.51489\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    if count == 4:\n",
    "        param.requires_grad = False\n",
    "    count += 1\n",
    "extraLayer = nn.Softmax()\n",
    "new_model = nn.Sequential(model, extraLayer)\n",
    "epochs = 100\n",
    "fit_early_stop(epochs, new_model, loss, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 40.000% \tLoss: 1.50309\n",
      "Epoch: 5 \tValidation accuracy: 46.000% \tLoss: 1.42651\n",
      "Epoch: 10 \tValidation accuracy: 47.333% \tLoss: 1.42269\n",
      "Epoch: 15 \tValidation accuracy: 48.667% \tLoss: 1.41738\n",
      "Epoch: 20 \tValidation accuracy: 48.000% \tLoss: 1.41531\n",
      "Epoch: 25 \tValidation accuracy: 48.667% \tLoss: 1.41251\n",
      "Epoch: 30 \tValidation accuracy: 48.667% \tLoss: 1.40919\n",
      "Epoch: 35 \tValidation accuracy: 48.667% \tLoss: 1.40402\n",
      "Epoch: 40 \tValidation accuracy: 50.000% \tLoss: 1.40138\n",
      "Epoch: 45 \tValidation accuracy: 50.000% \tLoss: 1.39931\n",
      "Epoch: 50 \tValidation accuracy: 50.667% \tLoss: 1.39764\n",
      "Epoch: 55 \tValidation accuracy: 51.333% \tLoss: 1.39688\n",
      "Epoch: 60 \tValidation accuracy: 51.333% \tLoss: 1.39588\n",
      "Epoch: 65 \tValidation accuracy: 51.333% \tLoss: 1.39560\n",
      "Epoch: 70 \tValidation accuracy: 52.000% \tLoss: 1.39405\n",
      "Epoch: 75 \tValidation accuracy: 52.000% \tLoss: 1.39290\n",
      "Epoch: 80 \tValidation accuracy: 52.000% \tLoss: 1.39195\n",
      "Epoch: 85 \tValidation accuracy: 52.000% \tLoss: 1.39185\n",
      "Epoch: 90 \tValidation accuracy: 52.000% \tLoss: 1.39168\n",
      "Epoch: 95 \tValidation accuracy: 52.000% \tLoss: 1.39160\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.parameters():\n",
    "    if count > 1:\n",
    "        param.requires_grad = False\n",
    "    count += 1\n",
    "    \n",
    "extraLayer = nn.Softmax()\n",
    "new_model = nn.Sequential(model, extraLayer)\n",
    "epochs = 100\n",
    "fit_early_stop(epochs, new_model, loss, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tValidation accuracy: 52.000% \tLoss: 1.39068\n",
      "Epoch: 5 \tValidation accuracy: 51.333% \tLoss: 1.38851\n",
      "Epoch: 10 \tValidation accuracy: 50.000% \tLoss: 1.38884\n",
      "Epoch: 15 \tValidation accuracy: 50.667% \tLoss: 1.39127\n",
      "Epoch: 20 \tValidation accuracy: 51.333% \tLoss: 1.38992\n",
      "Epoch: 25 \tValidation accuracy: 50.667% \tLoss: 1.38936\n",
      "Epoch: 30 \tValidation accuracy: 51.333% \tLoss: 1.39187\n",
      "Epoch: 35 \tValidation accuracy: 51.333% \tLoss: 1.38797\n",
      "Epoch: 40 \tValidation accuracy: 50.667% \tLoss: 1.39090\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "extraLayer = nn.Softmax()\n",
    "new_model = nn.Sequential(model, extraLayer)\n",
    "epochs = 100\n",
    "fit_early_stop(epochs, new_model, loss, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkitenv",
   "language": "python",
   "name": "rdkitenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
